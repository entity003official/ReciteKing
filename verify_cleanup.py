#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯æ±‡æ¸…ç†éªŒè¯è„šæœ¬
éªŒè¯æ‰€æœ‰çš„æ‹¬å·å’Œçœç•¥å·æ¨¡å¼æ˜¯å¦å·²æ­£ç¡®æ¸…ç†
"""

import pandas as pd
import os
import re

def verify_vocabulary_cleaning():
    """éªŒè¯è¯æ±‡æ¸…ç†ç»“æœ"""
    print("å¼€å§‹éªŒè¯è¯æ±‡æ¸…ç†ç»“æœ...")
    print("=" * 60)
    
    # å®šä¹‰éœ€è¦æ£€æŸ¥çš„ç›®å½•
    vocab_dir = r'e:\work\2025_8_24ReciteKing\web\data\vocabulary'
    
    if not os.path.exists(vocab_dir):
        print(f"ç›®å½•ä¸å­˜åœ¨: {vocab_dir}")
        return
    
    issues_found = []
    cleaned_entries = []
    
    # æ£€æŸ¥æ‰€æœ‰lessonæ–‡ä»¶
    for i in range(1, 26):  # lesson 1-25
        filename = f"lesson_{i:02d}_vocabulary.csv"
        file_path = os.path.join(vocab_dir, filename)
        
        if not os.path.exists(file_path):
            continue
        
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
        except:
            continue
        
        print(f"\næ£€æŸ¥æ–‡ä»¶: {filename}")
        print("-" * 40)
        
        for index, row in df.iterrows():
            if len(row) >= 3:
                kana_reading = str(row.iloc[2])  # å‡åè¯»éŸ³åˆ—
                kanji_reading = str(row.iloc[3]) if len(row) >= 4 else ""  # æ±‰å­—åˆ—
                meaning = str(row.iloc[4]) if len(row) >= 5 else ""  # é‡Šä¹‰åˆ—
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æœªæ¸…ç†çš„æ¨¡å¼
                if 'â€¦' in kana_reading and 'ï¼ˆ' in kana_reading:
                    issues_found.append({
                        'file': filename,
                        'row': index + 1,
                        'kana': kana_reading,
                        'kanji': kanji_reading,
                        'meaning': meaning,
                        'issue': 'å‡åä¸­ä»æœ‰æœªæ¸…ç†çš„çœç•¥å·å’Œæ‹¬å·'
                    })
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤šç­”æ¡ˆåˆ†éš”ç¬¦
                if '|' in kana_reading:
                    variants = kana_reading.split('|')
                    cleaned_entries.append({
                        'file': filename,
                        'row': index + 1,
                        'original_kana': kana_reading,
                        'variants': variants,
                        'kanji': kanji_reading,
                        'meaning': meaning
                    })
                    print(f"  âœ… ç¬¬{index+1}è¡Œ: {kana_reading} -> æ”¯æŒå¤šç­”æ¡ˆ: {', '.join(variants)}")
                
                # æ£€æŸ¥æ±‰å­—åˆ—ä¸­çš„çœç•¥å·
                if 'â€¦' in kanji_reading:
                    print(f"  ğŸ“ ç¬¬{index+1}è¡Œ: æ±‰å­—ä¸­åŒ…å«çœç•¥å·: {kanji_reading}")
    
    # è¾“å‡ºéªŒè¯ç»“æœ
    print("\n" + "=" * 60)
    print("éªŒè¯ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    if issues_found:
        print(f"âš ï¸ å‘ç° {len(issues_found)} ä¸ªæœªå®Œå…¨æ¸…ç†çš„æ¡ç›®:")
        for issue in issues_found:
            print(f"  {issue['file']} ç¬¬{issue['row']}è¡Œ: {issue['kana']} ({issue['meaning']})")
    else:
        print("âœ… æ‰€æœ‰æœ‰é—®é¢˜çš„å‡åè¯»éŸ³å‡å·²æ¸…ç†å®Œæ¯•ï¼")
    
    if cleaned_entries:
        print(f"\nâœ… æˆåŠŸæ¸…ç†å¹¶æ”¯æŒå¤šç­”æ¡ˆçš„æ¡ç›®: {len(cleaned_entries)} ä¸ª")
        unique_patterns = set()
        for entry in cleaned_entries:
            pattern = ' | '.join(entry['variants'])
            unique_patterns.add(pattern)
        
        print("æ”¯æŒçš„å¤šç­”æ¡ˆæ¨¡å¼:")
        for pattern in sorted(unique_patterns):
            print(f"  â€¢ {pattern}")
    
    # ä¿å­˜éªŒè¯æŠ¥å‘Š
    with open("è¯æ±‡æ¸…ç†éªŒè¯æŠ¥å‘Š.txt", 'w', encoding='utf-8') as f:
        f.write("è¯æ±‡æ¸…ç†éªŒè¯æŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        
        if issues_found:
            f.write(f"æœªå®Œå…¨æ¸…ç†çš„æ¡ç›® ({len(issues_found)} ä¸ª):\n")
            f.write("-" * 30 + "\n")
            for issue in issues_found:
                f.write(f"{issue['file']} ç¬¬{issue['row']}è¡Œ:\n")
                f.write(f"  å‡å: {issue['kana']}\n")
                f.write(f"  æ±‰å­—: {issue['kanji']}\n")
                f.write(f"  é‡Šä¹‰: {issue['meaning']}\n")
                f.write(f"  é—®é¢˜: {issue['issue']}\n\n")
        else:
            f.write("âœ… æ‰€æœ‰æœ‰é—®é¢˜çš„å‡åè¯»éŸ³å‡å·²æ¸…ç†å®Œæ¯•ï¼\n\n")
        
        if cleaned_entries:
            f.write(f"æ”¯æŒå¤šç­”æ¡ˆçš„æ¡ç›® ({len(cleaned_entries)} ä¸ª):\n")
            f.write("-" * 30 + "\n")
            for entry in cleaned_entries:
                f.write(f"{entry['file']} ç¬¬{entry['row']}è¡Œ:\n")
                f.write(f"  å‡åå˜ä½“: {' | '.join(entry['variants'])}\n")
                f.write(f"  æ±‰å­—: {entry['kanji']}\n")
                f.write(f"  é‡Šä¹‰: {entry['meaning']}\n\n")
    
    print(f"\nè¯¦ç»†éªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: è¯æ±‡æ¸…ç†éªŒè¯æŠ¥å‘Š.txt")
    
    return len(issues_found) == 0, len(cleaned_entries)

def main():
    """ä¸»å‡½æ•°"""
    success, cleaned_count = verify_vocabulary_cleaning()
    
    print(f"\n{'âœ… éªŒè¯é€šè¿‡' if success else 'âŒ éªŒè¯å¤±è´¥'}")
    print(f"æ”¯æŒå¤šç­”æ¡ˆçš„è¯æ±‡æ•°é‡: {cleaned_count}")
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰éœ€è¦æ¸…ç†çš„è¯æ±‡å·²æ­£ç¡®å¤„ç†ï¼")
        print("ğŸ’¡ å»ºè®®:")
        print("  1. æµ‹è¯•word-practice.htmlä¸­çš„å¤šç­”æ¡ˆéªŒè¯åŠŸèƒ½")
        print("  2. éªŒè¯ç”¨æˆ·è¾“å…¥'ãµã‚“'æˆ–'ã·ã‚“'éƒ½èƒ½æ­£ç¡®è¯†åˆ«")
        print("  3. æ£€æŸ¥å…¶ä»–å¤šç­”æ¡ˆè¯æ±‡çš„éªŒè¯æ•ˆæœ")
    else:
        print("\nâš ï¸ ä»æœ‰éƒ¨åˆ†è¯æ±‡éœ€è¦æ‰‹åŠ¨å¤„ç†ï¼Œè¯·æŸ¥çœ‹éªŒè¯æŠ¥å‘Š")

if __name__ == "__main__":
    main()
